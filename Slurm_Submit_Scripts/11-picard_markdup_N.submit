#!/usr/bin/bash
#SBATCH --mail-type=ALL,TIME_LIMIT
#SBATCH --mail-user=jacojam@ohsu.edu
#SBATCH --time=1-12:00:00
#SBATCH -a 1-5
#SBATCH --error=/home/exacloud/lustre1/jjacobs/osteo_logs/stderr.markdup_N_%a
#SBATCH --output=/home/exacloud/lustre1/jjacobs/osteo_logs/stout.markdup_N_%a

#This submit script will run picard tools using java and will use the tool
#"MarkDuplicates to mark any duplicate reads from a sequence alignment file
#
#In previous workflows, I've used the "SORT_ORDER=coordinate" function in
#the "picard_addorreplacereadgroups" step.  However, since readgroups were
#added at the alignment stage, this wasn't included in this workflow.
#Let's see if it works downstream.
#
#Per the GATK pipeline, I've also included the CREATE_INDEX=true command
#which will create a index for the outputed .bam file.  This is needed
#for downstream GATK tools
#
#Also per the GATK pipeline, I've included the VALIDATION_STRINGENCY=SILENT
#command.  Not sure if this is necessary.
#
#The picard program is located in
#/home/exacloud/lustre1/mcweeney_lab/jacojam/programs/picard
#
#Here I set a common directory so I don't have to
#type it multiple times.
#
COMMON_DIR="/home/exacloud/lustre1/jjacobs"
PICARD_DIR=$COMMON_DIR"/programs/picard"

rns=(SJOS004_G SJOS005_G SJOS006_G SJOS007_G SJOS008_G)

ALIGNMENT_RUN=${rns[${SLURM_ARRAY_TASK_ID}-1]}
#ALIGNMENT_RUN="SJOS001101_G1"

INPUT_FILE=$COMMON_DIR"/data/osteo/"$ALIGNMENT_RUN"/aligned.bam"
OUTPUT_DIR=$COMMON_DIR"/data/osteo/"$ALIGNMENT_RUN


srun /usr/bin/java -Xmx8G -jar $PICARD_DIR/picard.jar MarkDuplicates \
I=$INPUT_FILE \
O=$OUTPUT_DIR/rg_added_aligned_MarkedDup.bam \
CREATE_INDEX=true \
TAGGING_POLICY=All \
VALIDATION_STRINGENCY=SILENT \
M=$OUTPUT_DIR/Markdup_metrics.txt \
TMP_DIR=$COMMON_DIR/submit_scripts/osteo_Workflow/working_temp_mdn_${SLURM_ARRAY_TASK_ID}
